{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "# import tkinter\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data formatting en reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0 # Start of sentence\n",
    "EOS_token = 1 # End of sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Language:\n",
    "    def __init__(self):\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: 'SOS', 1: 'EOS'}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "    def readLang(self, s):\n",
    "        for index, value in s.items():\n",
    "            value = normalizeString(value)\n",
    "            self.addSentence(value)\n",
    "\n",
    "    def showLang(self):\n",
    "        print(\"-- NL Language\")\n",
    "        print(\"Word count: \", sum(self.word2count.values()))\n",
    "        print(\"Vocabe size: \", self.n_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRLanguage:\n",
    "    def __init__(self):\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: 'SOS', 1: 'EOS'}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(', '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "    def readLang(self, s):\n",
    "        for index, value in s.items():\n",
    "            value = normalizeMRString(value)\n",
    "            self.addSentence(value)\n",
    "\n",
    "    def showLang(self):\n",
    "        print(\"-- MR Language\")\n",
    "        print(\"Word count: \", sum(self.word2count.values()))\n",
    "        print(\"Vocabe size: \", self.n_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?_]+\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "def normalizeMRString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r'\\[[^]]*\\]', r\"\", s) # TODO: Data in de square brackets is lost!!\n",
    "    # s = re.sub(r\"[\\[*\\]]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence, delimeter=' '):\n",
    "    indices = [lang.word2index[word] for word in sentence.split(delimeter)]\n",
    "    return torch.tensor(indices)\n",
    "\n",
    "def sentenceFromIndexes(lang, indexes, delimeter=' '):\n",
    "    sentence = ''\n",
    "    for i in indexes:\n",
    "        sentence += str(lang.index2word[i.item()]) + delimeter\n",
    "    \n",
    "    return sentence\n",
    "\n",
    "\n",
    "def get_output_data(file):\n",
    "    corpus_df = pd.read_csv(file)\n",
    "    lang_df = corpus_df['ref']\n",
    "\n",
    "    natural_lang = Language()\n",
    "    natural_lang.readLang(lang_df)\n",
    "    # corpus_df['ref'] = corpus_df['ref'].astype(str) + ' eos'\n",
    "    corpus_df['ref'] = corpus_df['ref'].apply(lambda x: normalizeString(x))\n",
    "    corpus_df['ref'] = corpus_df['ref'].apply(lambda x: indexesFromSentence(natural_lang, x))\n",
    "\n",
    "    return corpus_df['ref'], natural_lang\n",
    "\n",
    "def get_input_data(file):\n",
    "    corpus_df = pd.read_csv(file)\n",
    "    lang_df = corpus_df['mr']\n",
    "\n",
    "    mr_lang = MRLanguage()\n",
    "    mr_lang.readLang(corpus_df['mr'])\n",
    "    # corpus_df['mr'] = corpus_df['mr'].astype(str) + ', eos'\n",
    "    corpus_df['mr'] = corpus_df['mr'].apply(lambda x: normalizeMRString(x))\n",
    "    corpus_df['mr'] = corpus_df['mr'].apply(lambda x: indexesFromSentence(mr_lang, x, delimeter=\", \"))\n",
    "\n",
    "    return corpus_df['mr'], mr_lang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading...\n",
      "-- MR Language\n",
      "Word count:  10632\n",
      "Vocabe size:  10\n",
      "None\n",
      "-- NL Language\n",
      "Word count:  32610\n",
      "Vocabe size:  671\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# GET DATA\n",
    "print(\"Reading...\")\n",
    "path = \"delexicalized/delex_only.csv\"\n",
    "input_data, mr_lang = get_input_data(path) #TODO: Correctly read all info of labels\n",
    "target_data, nl_lang = get_output_data(path)\n",
    "\n",
    "print(mr_lang.showLang())\n",
    "print(nl_lang.showLang())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        \n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=75):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=75):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):   \n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "    \n",
    "    for di in range(target_length):\n",
    "        decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "            decoder_input, decoder_hidden, encoder_outputs)\n",
    "        topv, topi = decoder_output.topk(1)\n",
    "        decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "        \n",
    "        loss += criterion(decoder_output, target_tensor[di])\n",
    "        if decoder_input.item() == EOS_token:\n",
    "            break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_epoch, learning_rate=0.01):\n",
    "    print(\"Started training!\")\n",
    "    \n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for epoch in range(1, n_epoch + 1):\n",
    "        print(epoch)\n",
    "        for i in range(len(input_data)):\n",
    "            input_tensor = input_data[i].view(-1, 1)\n",
    "            target_tensor = target_data[i].view(-1, 1)\n",
    "    #         print(\"Input: \", input_tensor)\n",
    "    #         print(\"Target: \", target_tensor)\n",
    "\n",
    "\n",
    "            loss = train(input_tensor, target_tensor, encoder,\n",
    "                         decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "            print_loss_total += loss\n",
    "            plot_loss_total += loss\n",
    "\n",
    "            \n",
    "        print_loss_avg = print_loss_total / len(input_data)\n",
    "        print_loss_total = 0\n",
    "        print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / n_epoch),\n",
    "                                     epoch, epoch / n_epoch * 100, print_loss_avg))\n",
    "\n",
    "        plot_loss_avg = plot_loss_total / len(input_data)\n",
    "        plot_losses.append(plot_loss_avg)\n",
    "        plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)\n",
    "    print(\"Done!\")\n",
    "    return plot_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, input_tensor, max_length=75):\n",
    "    with torch.no_grad():\n",
    "#         sentence = sentenceFromIndexes(mr_lang, input_tensor, delimeter=\", \")\n",
    "#         input_tensor = indexesFromSentence(mr_lang, sentence, delimeter=\", \")\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(nl_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        index = random.randint(0, len(input_data) - 1)\n",
    "        input_sentence = sentenceFromIndexes(mr_lang, input_data[index], delimeter=\", \")\n",
    "        target_sentence = sentenceFromIndexes(nl_lang, target_data[index], delimeter=\" \")\n",
    "        \n",
    "        print('>', input_sentence)\n",
    "        print('=', target_sentence)\n",
    "        output_words, attentions = evaluate(encoder, decoder, input_data[i])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started training!\n",
      "1\n",
      "2m 15s (- 223m 14s) (1 1%) 3.7979\n",
      "2\n",
      "4m 31s (- 221m 53s) (2 2%) 3.5993\n",
      "3\n",
      "6m 51s (- 221m 50s) (3 3%) 3.5603\n",
      "4\n",
      "9m 13s (- 221m 13s) (4 4%) 3.5366\n",
      "5\n",
      "11m 34s (- 219m 57s) (5 5%) 3.5184\n",
      "6\n",
      "13m 56s (- 218m 19s) (6 6%) 3.5032\n",
      "7\n",
      "16m 17s (- 216m 23s) (7 7%) 3.4886\n",
      "8\n",
      "18m 38s (- 214m 27s) (8 8%) 3.4753\n",
      "9\n",
      "21m 0s (- 212m 20s) (9 9%) 3.4638\n",
      "10\n",
      "23m 21s (- 210m 16s) (10 10%) 3.4496\n",
      "11\n",
      "25m 42s (- 208m 3s) (11 11%) 3.4375\n",
      "12\n",
      "28m 3s (- 205m 46s) (12 12%) 3.4263\n",
      "13\n",
      "30m 26s (- 203m 42s) (13 13%) 3.4132\n",
      "14\n",
      "32m 47s (- 201m 25s) (14 14%) 3.4008\n",
      "15\n",
      "35m 8s (- 199m 9s) (15 15%) 3.3861\n",
      "16\n",
      "37m 29s (- 196m 49s) (16 16%) 3.3709\n",
      "17\n",
      "39m 50s (- 194m 31s) (17 17%) 3.3548\n",
      "18\n",
      "42m 10s (- 192m 8s) (18 18%) 3.3387\n",
      "19\n",
      "44m 31s (- 189m 47s) (19 19%) 3.3246\n",
      "20\n",
      "46m 50s (- 187m 22s) (20 20%) 3.3050\n",
      "21\n",
      "49m 11s (- 185m 1s) (21 21%) 3.2866\n",
      "22\n",
      "51m 31s (- 182m 40s) (22 22%) 3.2672\n",
      "23\n",
      "53m 51s (- 180m 19s) (23 23%) 3.2514\n",
      "24\n",
      "56m 10s (- 177m 54s) (24 24%) 3.2326\n",
      "25\n",
      "58m 30s (- 175m 30s) (25 25%) 3.2114\n",
      "26\n",
      "60m 52s (- 173m 16s) (26 26%) 3.1911\n",
      "27\n",
      "63m 11s (- 170m 51s) (27 27%) 3.1885\n",
      "28\n",
      "65m 30s (- 168m 27s) (28 28%) 3.1628\n",
      "29\n",
      "67m 49s (- 166m 4s) (29 28%) 3.1501\n",
      "30\n",
      "70m 8s (- 163m 40s) (30 30%) 3.1199\n",
      "31\n",
      "72m 27s (- 161m 17s) (31 31%) 3.1102\n",
      "32\n",
      "74m 46s (- 158m 54s) (32 32%) 3.1086\n",
      "33\n",
      "77m 5s (- 156m 31s) (33 33%) 3.0970\n",
      "34\n",
      "79m 25s (- 154m 10s) (34 34%) 3.0957\n",
      "35\n",
      "81m 43s (- 151m 46s) (35 35%) 3.0883\n",
      "36\n",
      "84m 3s (- 149m 25s) (36 36%) 3.0760\n",
      "37\n",
      "86m 21s (- 147m 2s) (37 37%) 3.0727\n",
      "38\n",
      "88m 39s (- 144m 39s) (38 38%) 3.0617\n",
      "39\n",
      "90m 58s (- 142m 16s) (39 39%) 3.0814\n",
      "40\n",
      "93m 15s (- 139m 53s) (40 40%) 3.0866\n",
      "41\n",
      "95m 32s (- 137m 29s) (41 41%) 3.0760\n",
      "42\n",
      "97m 50s (- 135m 6s) (42 42%) 3.0734\n",
      "43\n",
      "100m 8s (- 132m 45s) (43 43%) 3.0729\n",
      "44\n",
      "102m 27s (- 130m 23s) (44 44%) 3.0695\n",
      "45\n",
      "104m 45s (- 128m 2s) (45 45%) 3.0449\n",
      "46\n",
      "107m 2s (- 125m 39s) (46 46%) 3.0127\n",
      "47\n",
      "109m 19s (- 123m 17s) (47 47%) 3.0164\n",
      "48\n",
      "111m 37s (- 120m 55s) (48 48%) 3.0284\n",
      "49\n",
      "113m 54s (- 118m 33s) (49 49%) 3.0228\n",
      "50\n",
      "116m 11s (- 116m 11s) (50 50%) 3.0250\n",
      "51\n",
      "118m 28s (- 113m 49s) (51 51%) 3.0301\n",
      "52\n",
      "120m 47s (- 111m 29s) (52 52%) 3.0200\n",
      "53\n",
      "123m 4s (- 109m 8s) (53 53%) 3.0486\n",
      "54\n",
      "125m 21s (- 106m 47s) (54 54%) 3.0855\n",
      "55\n",
      "127m 38s (- 104m 25s) (55 55%) 3.0736\n",
      "56\n",
      "129m 56s (- 102m 5s) (56 56%) 3.0462\n",
      "57\n",
      "132m 12s (- 99m 44s) (57 56%) 3.0534\n",
      "58\n",
      "134m 29s (- 97m 23s) (58 57%) 3.0760\n",
      "59\n",
      "136m 46s (- 95m 2s) (59 59%) 3.1356\n",
      "60\n",
      "139m 3s (- 92m 42s) (60 60%) 3.1457\n",
      "61\n",
      "141m 19s (- 90m 21s) (61 61%) 3.0834\n",
      "62\n",
      "143m 36s (- 88m 0s) (62 62%) 3.0874\n",
      "63\n",
      "145m 53s (- 85m 40s) (63 63%) 3.0664\n",
      "64\n",
      "148m 9s (- 83m 20s) (64 64%) 3.0573\n",
      "65\n",
      "150m 26s (- 81m 0s) (65 65%) 3.0926\n",
      "66\n",
      "152m 43s (- 78m 40s) (66 66%) 3.0881\n",
      "67\n",
      "154m 58s (- 76m 20s) (67 67%) 3.1046\n",
      "68\n",
      "157m 15s (- 74m 0s) (68 68%) 3.1048\n",
      "69\n",
      "159m 32s (- 71m 40s) (69 69%) 3.1096\n",
      "70\n",
      "161m 48s (- 69m 20s) (70 70%) 3.0825\n",
      "71\n",
      "164m 4s (- 67m 1s) (71 71%) 3.0776\n",
      "72\n",
      "166m 21s (- 64m 41s) (72 72%) 3.0600\n",
      "73\n",
      "168m 37s (- 62m 22s) (73 73%) 3.0637\n",
      "74\n",
      "170m 53s (- 60m 2s) (74 74%) 3.1367\n",
      "75\n",
      "173m 9s (- 57m 43s) (75 75%) 3.1411\n",
      "76\n",
      "175m 26s (- 55m 24s) (76 76%) 3.1563\n",
      "77\n",
      "177m 42s (- 53m 5s) (77 77%) 3.3327\n",
      "78\n",
      "180m 1s (- 50m 46s) (78 78%) 3.3258\n",
      "79\n",
      "182m 18s (- 48m 27s) (79 79%) 3.3529\n",
      "80\n",
      "184m 34s (- 46m 8s) (80 80%) 3.4422\n",
      "81\n",
      "186m 51s (- 43m 49s) (81 81%) 3.4032\n",
      "82\n",
      "189m 7s (- 41m 30s) (82 82%) 3.3863\n",
      "83\n",
      "191m 24s (- 39m 12s) (83 83%) 3.3283\n",
      "84\n",
      "193m 40s (- 36m 53s) (84 84%) 3.2892\n",
      "85\n",
      "195m 56s (- 34m 34s) (85 85%) 3.3404\n",
      "86\n",
      "198m 12s (- 32m 15s) (86 86%) 3.3583\n",
      "87\n",
      "200m 27s (- 29m 57s) (87 87%) 3.3180\n",
      "88\n",
      "202m 44s (- 27m 38s) (88 88%) 3.4851\n",
      "89\n",
      "205m 0s (- 25m 20s) (89 89%) 3.7385\n",
      "90\n",
      "207m 16s (- 23m 1s) (90 90%) 3.5393\n",
      "91\n",
      "209m 31s (- 20m 43s) (91 91%) 3.4630\n",
      "92\n",
      "211m 48s (- 18m 25s) (92 92%) 3.4197\n",
      "93\n",
      "214m 3s (- 16m 6s) (93 93%) 3.3819\n",
      "94\n",
      "216m 19s (- 13m 48s) (94 94%) 3.3575\n",
      "95\n",
      "218m 35s (- 11m 30s) (95 95%) 3.6125\n",
      "96\n",
      "220m 50s (- 9m 12s) (96 96%) 3.5956\n",
      "97\n",
      "223m 6s (- 6m 54s) (97 97%) 4.0470\n",
      "98\n",
      "225m 22s (- 4m 35s) (98 98%) 3.9083\n",
      "99\n",
      "227m 38s (- 2m 17s) (99 99%) 3.6901\n",
      "100\n",
      "229m 54s (- 0m 0s) (100 100%) 3.6152\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "n_epoch = 100\n",
    "\n",
    "hidden_size = 256\n",
    "\n",
    "encoder1 = EncoderRNN(mr_lang.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, nl_lang.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "plot_losses = trainIters(encoder1, attn_decoder1, n_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> name, food, pricerange, area, familyfriendly, \n",
      "= located food_x city centre is name_x a cheap area_x . \n",
      "< name_x eattype_x a eattype_x a near_x near_x near_x near_x . near_x . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "\n",
      "> name, food, pricerange, customer rating, near, \n",
      "= the name_x sells food_x food near near_x . the customer rating is customer rating_x and the price pricerange_x . \n",
      "< name_x is a eattype_x eattype_x food_x food food food food food food food food food food food food food food food food food food food food food food food food food food food food food food food food food food food food food food food food food food food food food food food food food food food food food food food food food food food food food food food food food food food food food\n",
      "\n",
      "> name, food, pricerange, customer rating, familyfriendly, near, \n",
      "= for a familyfriendly_x food_x place with pricerange_x places and customer rating_x stars there is name_x which is near the near_x \n",
      "< name_x is familyfriendly_x familyfriendly_x area_x area_x area_x food_x area_x in in near_x in near_x in near_x in near_x in near_x in in in and in and in and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and . . . . .\n",
      "\n",
      "> name, food, pricerange, area, familyfriendly, \n",
      "= name_x is located in the area_x area and features pricerange_x priced food_x food and is familyfriendly_x \n",
      "< name_x is area_x area_x area_x in the food the food the the the food the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "\n",
      "> name, eattype, food, pricerange, familyfriendly, near, \n",
      "= name_x familyfriendly_x near to the near_x in dulwich and pricerange_x nice and fresh food_x foods for it s visitor on affordable prices . unfortunately it is not kids friendly . \n",
      "< name_x is area_x food_x area_x near near near_x near_x near_x near_x near_x near_x near_x near_x near_x near_x near_x rating rating rating rating rating rating rating rating rating rating rating rating rating rating rating rating rating rating rating rating rating rating rating rating rating rating rating rating rating rating rating rating rating rating rating rating rating rating rating rating rating rating rating rating rating rating rating rating rating rating rating rating rating rating rating rating rating\n",
      "\n",
      "> name, food, pricerange, area, familyfriendly, \n",
      "= a area_x burger food_x name_x is a great venue familyfriendly_x . \n",
      "< name_x is food_x restaurant restaurant food restaurant in area_x food food food food . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "\n",
      "> name, food, area, familyfriendly, near, \n",
      "= name_x is a familyfriendly_x food_x food restaurant area_x the city near near_x . \n",
      "< name_x is food_x in area_x area_x area_x area_x area_x area_x area_x area_x and and and and and and and and and and . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "\n",
      "> name, eattype, food, pricerange, area, familyfriendly, \n",
      "= there is a eattype_x that is pricerange_x priced called name_x in the area_x area that serves food_x food and is familyfriendly_x \n",
      "< name_x familyfriendly_x familyfriendly_x near near in in food food area_x price . price . price . price . price . price . price . price . price . price . price . price . price . price . price . price . . . price . price . . . price . price . . . price . price . . . . . . . . . . . . . . . .\n",
      "\n",
      "> name, eattype, food, customer rating, area, familyfriendly, near, \n",
      "= there is a five food_x name_x located customer rating_x near_x . it area_x \n",
      "< name_x is eattype_x eattype_x eattype_x in in area_x area_x food food and and and and and and and and and and and and and and and and and and and and and and and and and and and and and . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "\n",
      "> name, food, customer rating, familyfriendly, \n",
      "= name_x is an customer rating_x rated familyfriendly_x restaurant serving food_x . \n",
      "< name_x food_x food_x food_x food_x food_x food_x food_x food_x food_x food_x food_x food the the the the customer customer customer customer rating rating rating rating . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
